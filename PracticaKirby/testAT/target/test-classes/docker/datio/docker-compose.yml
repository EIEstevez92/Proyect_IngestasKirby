hadoop:
  build: ./hadoop
  container_name: hadoop${BUILD_ID}
  ports:
    - 9000:9000
    - 50070:50070
    - 50075:50075
  command: bash -c "/etc/bootstrap.sh -d"

node:
  build: ./node
  container_name: node${BUILD_ID}
  ports:
    - 8080:8080
  command: bash -c "cd /opt/restServer && npm install && npm start"

nginx:
  build: ./nginx
  container_name: nginx${BUILD_ID}

master:
  build: ./spark
  command: bin/spark-class org.apache.spark.deploy.master.Master -h master
  container_name: spark_master${BUILD_ID}
  hostname: master
  environment:
    MASTER: spark://master:7077
    SPARK_CONF_DIR: /conf
    SPARK_PUBLIC_DNS: localhost
    tokenization_app_name: cloud
    tokenization_app_pass: eG73ao2adAkZQl1PmYg
    tokenization_app_endpoint: LOCAL
    kirby_validation_enabled: "false"
  links:
    - hadoop
    - node
    - nginx
  expose:
    - 7001
    - 7002
    - 7003
    - 7004
    - 7005
    - 7006
    - 7077
    - 6066
  ports:
    - 4040:4040
    - 6066:6066
    - 7077:7077
    - 18080:8080
    - 5005:5005 #For remote debug

  volumes:
    - ./spark/conf/master:/conf
    - ./spark/kirby:/kirby

worker:
  build: ./spark
  command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://master:7077
  container_name: spark_worker${BUILD_ID}
  hostname: worker
  environment:
    SPARK_CONF_DIR: /conf
    SPARK_WORKER_CORES: 2
    SPARK_WORKER_MEMORY: 1g
    SPARK_WORKER_PORT: 8881
    SPARK_WORKER_WEBUI_PORT: 8081
    SPARK_PUBLIC_DNS: localhost
    tokenization_app_name: cloud
    tokenization_app_pass: eG73ao2adAkZQl1PmYg
    tokenization_app_endpoint: LOCAL
    kirby_validation_enabled: "false"
  links:
    - master
    - hadoop
  expose:
    - 7012
    - 7013
    - 7014
    - 7015
    - 7016
    - 8881
  ports:
    - 8081:8081
  volumes:
    - ./spark/conf/worker:/conf

